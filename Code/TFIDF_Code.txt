This file contains query used for TF IDF calculation using hive on GCP.

add jar /home/arifkhan89837/hivemall-all-0.6.0-incubating.jar;
source /home/arifkhan89837/define-all.hive;

hive> create temporary macro max2(x INT, y INT)
    > if(x>y,x,y);

hive> create temporary macro tfidf(tf FLOAT, df_t INT, n_docs INT)
    > tf * (log(10, CAST(n_docs as FLOAT)/max2(1,df_t)) + 1.0);

hive>  Create view topuser as select OwnerUserId, SUM(Score) AS AddedScore from hiveTable
    > WHERE OwnerUserId IS NOT NULL
    > GROUP BY OwnerUserId
    > ORDER BY AddedScore DESC
    > LIMIT 10;

hive> create or replace view topquery as select OwnerUserId, Body from hiveTable WHERE OwnerUserId IN (select OwnerUserId  
from topuser);

hive> create or replace view query_exploded
    > as select OwnerUserId, word
    > from topquery LATERAL VIEW explode(tokenize(Body,true)) t as word
    > where not is_stopword(word) and LENGTH(word) > 3;
  
  
hive> create or replace view topwords as
    > SELECT word, COUNT(word) AS add FROM query_exploded 
    > WHERE OwnerUserId IN (select OwnerUserId from topuser)
    > GROUP BY word
    > ORDER BY add DESC
    > LIMIT 10;
  
hive> create or replace view word_frequency as 
    > select OwnerUserId, word, freq from ( 
    > select OwnerUserId, tf(word) as word2freq
    > from query_exploded group by OwnerUserId ) t LATERAL VIEW explode(word2freq) t2 as word, freq;  
  
hive> create or replace view user_frequency as select word, count(distinct OwnerUserId) docs
    > from query_exploded group by word;
  
hive> set hivevar:n_docs=1;


hive> create or replace view tfidf as 
    > select tf.OwnerUserId, tf.word,tfidf(tf.freq, df.docs, ${n_docs}) as tfidf
    > from word_frequency tf JOIN user_frequency df ON (tf.word = df.word)
    > order by tfidf desc;
  
hive> select OwnerUserId, collect_list(feature(word, tfidf)) as features from 
    >   tfidf where word in (select word from topwords ) group by  OwnerUserId;